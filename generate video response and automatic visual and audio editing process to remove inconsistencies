import call request library 
import video file access manager


//sorting input output matches

intit matchingLibraries directory
intit library.convertfunc

def private_match.compare(libraires.name)
//this will compare two inputs

def video.final(API.1_[API2])

//this combines two files from two different APIs.  in our case it's the video generated by midjourney, runway, or canva and the audio generated by elevenlabs or chat.GPT's audio API

//nexxt we will overlay video and audio generated by the two APIs with the following process
def response.log(acces.private.generator.videofinal)description of a video the should be generated or a filter than can be applied to resolve the discrepency.  it also iincludes information about how the video should be spliced in, so for example, if it should be a clean cut, a b-roll the disolves in, a cutaway with a swoosh sound added, a simple overlay, a green screen, etc.. this process sends a second request to the necessary API with the appropriate visual enhancements, thus generating a revised version of the video.  the revsions between this function nd the API's calling for video generation (AKA the video editing and revision process) will run until this process returns a value of TRUE for "is this video quality sufficient?)  when the answer is true, the process updates the code with the video log, which is access and refered to by the view code (later in this script).

after that we need to ensure the video and audio actually match up and look good.  we also need to have a process to fix any discrepencies in the video and audio sequence.  this aensures there are no moments where the audio is the person talking but the video doesn't show their lips moving, and similar cases.  this will use a third API, which automatically reviews the syncronyzation of audio and video and suggests a description of what time stamps the odd parts happen.  the description includes a 


match.filetypeConvert(match[library.convert])

//this will convert libraries to th right file type

//
view code goes below

header['upload or record live video"]

button.dynamic[file.upload](Upload"]
//this will alolow user to upload video

paragraph["Or"]

Button["record live"](access camerica.device.local.camerica.frontfacing) 

//this accesses users front facing camera - uses dictionary terms. make sure you use right call request term for the verision of library you imported

//now you must update view code with box for displaying generated video and audio


frame.600.900px 
]
//make portrait with dimensions roughly size of phone screen, can modify or make dynamic later


   vide.player[vid.responselog]  this displays the video in the response log.  by default displays most recent video.  
